{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "from collections import OrderedDict\n",
    "from torchmeta.utils.data import BatchMetaDataLoader\n",
    "\n",
    "from maml.datasets import get_benchmark_by_name\n",
    "from maml.metalearners import ModelAgnosticMetaLearning\n",
    "from maml.metalearners import FlatModelAgnosticMetaLearning\n",
    "from maml.metalearners import SamModelAgnosticMetaLearning\n",
    "\n",
    "from sam import SAM\n",
    "from sam_folder.model.smooth_cross_entropy import smooth_crossentropy\n",
    "from sam_folder.utility.bypass_bn import enable_running_stats, disable_running_stats\n",
    "from sam_folder.model.wide_res_net import WideResNet\n",
    "from sam_folder.utility.step_lr import StepLR\n",
    "\n",
    "device = torch.device('cuda' if  torch.cuda.is_available() else 'cpu')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ways=5\n",
    "shots=1\n",
    "meta_lr=0.003\n",
    "fast_lr=0.5\n",
    "meta_batch_size=32\n",
    "\n",
    "benchmark = get_benchmark_by_name('omniglot',\n",
    "                                      './data',\n",
    "                                      ways,\n",
    "                                      shots,\n",
    "                                      shots,\n",
    "                                      hidden_size=64)\n",
    "\n",
    "meta_train_dataloader = BatchMetaDataLoader(benchmark.meta_train_dataset,\n",
    "                                            batch_size=32,\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=2,\n",
    "                                            pin_memory=True)\n",
    "meta_val_dataloader = BatchMetaDataLoader(benchmark.meta_val_dataset,\n",
    "                                            batch_size=16,\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=2,\n",
    "                                            pin_memory=True)\n",
    "\n",
    "meta_optimizer = torch.optim.Adam(benchmark.model.parameters(), lr=meta_lr)\n",
    "#base_optimizer = torch.optim.Adam\n",
    "#meta_optimizer = SAM(benchmark.model.parameters(), base_optimizer, rho=0.05,\n",
    "#                        adaptive=False, lr=meta_lr)\n",
    "metalearner = ModelAgnosticMetaLearning(benchmark.model,\n",
    "                                        meta_optimizer,\n",
    "                                        first_order=False,\n",
    "                                        num_adaptation_steps=1,\n",
    "                                        step_size=fast_lr,\n",
    "                                        loss_function=benchmark.loss_function,\n",
    "                                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1  : 100%|██████████| 500/500 [00:33<00:00, 14.83it/s, accuracy=0.9334, loss=0.2076]\n",
      "Epoch 2  : 100%|██████████| 500/500 [00:33<00:00, 14.98it/s, accuracy=0.9479, loss=0.1586]\n",
      "Epoch 3  : 100%|██████████| 500/500 [00:33<00:00, 15.13it/s, accuracy=0.9636, loss=0.1125]\n",
      "Epoch 4  : 100%|██████████| 500/500 [00:32<00:00, 15.21it/s, accuracy=0.9667, loss=0.0999]\n",
      "Epoch 5  : 100%|██████████| 500/500 [00:32<00:00, 15.34it/s, accuracy=0.9714, loss=0.0865]\n",
      "Epoch 6  : 100%|██████████| 500/500 [00:33<00:00, 15.07it/s, accuracy=0.9769, loss=0.0722]\n",
      "Epoch 7  : 100%|██████████| 500/500 [00:33<00:00, 15.11it/s, accuracy=0.9720, loss=0.0853]\n",
      "Epoch 8  : 100%|██████████| 500/500 [00:33<00:00, 15.10it/s, accuracy=0.9764, loss=0.0701]\n",
      "Epoch 9  : 100%|██████████| 500/500 [00:31<00:00, 15.83it/s, accuracy=0.9761, loss=0.0730]\n",
      "Epoch 10 : 100%|██████████| 500/500 [00:34<00:00, 14.68it/s, accuracy=0.9811, loss=0.0568]\n",
      "Epoch 11 : 100%|██████████| 500/500 [00:34<00:00, 14.69it/s, accuracy=0.9781, loss=0.0652]\n",
      "Epoch 12 : 100%|██████████| 500/500 [00:32<00:00, 15.40it/s, accuracy=0.9808, loss=0.0576]\n",
      "Epoch 13 : 100%|██████████| 500/500 [00:33<00:00, 14.80it/s, accuracy=0.9821, loss=0.0549]\n",
      "Epoch 14 : 100%|██████████| 500/500 [00:34<00:00, 14.60it/s, accuracy=0.9844, loss=0.0464]\n",
      "Epoch 15 : 100%|██████████| 500/500 [00:33<00:00, 15.01it/s, accuracy=0.9834, loss=0.0486]\n",
      "Epoch 16 : 100%|██████████| 500/500 [00:34<00:00, 14.68it/s, accuracy=0.9865, loss=0.0403]\n",
      "Epoch 17 : 100%|██████████| 500/500 [00:32<00:00, 15.31it/s, accuracy=0.9841, loss=0.0457]\n",
      "Epoch 18 : 100%|██████████| 500/500 [00:32<00:00, 15.23it/s, accuracy=0.9884, loss=0.0364]\n",
      "Epoch 19 : 100%|██████████| 500/500 [00:33<00:00, 15.10it/s, accuracy=0.9877, loss=0.0361]\n",
      "Epoch 20 : 100%|██████████| 500/500 [00:34<00:00, 14.65it/s, accuracy=0.9860, loss=0.0419]\n",
      "Epoch 21 : 100%|██████████| 500/500 [00:34<00:00, 14.58it/s, accuracy=0.9864, loss=0.0408]\n",
      "Epoch 22 : 100%|██████████| 500/500 [00:33<00:00, 14.91it/s, accuracy=0.9859, loss=0.0427]\n",
      "Epoch 23 : 100%|██████████| 500/500 [00:34<00:00, 14.53it/s, accuracy=0.9871, loss=0.0370]\n",
      "Epoch 24 : 100%|██████████| 500/500 [00:32<00:00, 15.32it/s, accuracy=0.9867, loss=0.0362]\n",
      "Epoch 25 : 100%|██████████| 500/500 [00:33<00:00, 14.81it/s, accuracy=0.9871, loss=0.0377]\n",
      "Epoch 26 : 100%|██████████| 500/500 [00:34<00:00, 14.70it/s, accuracy=0.9898, loss=0.0298]\n",
      "Epoch 27 : 100%|██████████| 500/500 [00:34<00:00, 14.63it/s, accuracy=0.9891, loss=0.0323]\n",
      "Epoch 28 : 100%|██████████| 500/500 [00:32<00:00, 15.25it/s, accuracy=0.9889, loss=0.0316]\n",
      "Epoch 29 : 100%|██████████| 500/500 [00:33<00:00, 15.11it/s, accuracy=0.9892, loss=0.0299]\n",
      "Epoch 30 : 100%|██████████| 500/500 [00:33<00:00, 14.96it/s, accuracy=0.9893, loss=0.0297]\n",
      "Epoch 31 : 100%|██████████| 500/500 [00:33<00:00, 14.77it/s, accuracy=0.9887, loss=0.0332]\n",
      "Epoch 32 : 100%|██████████| 500/500 [00:33<00:00, 14.77it/s, accuracy=0.9884, loss=0.0324]\n",
      "Epoch 33 : 100%|██████████| 500/500 [00:33<00:00, 14.89it/s, accuracy=0.9884, loss=0.0333]\n",
      "Epoch 34 : 100%|██████████| 500/500 [00:35<00:00, 14.17it/s, accuracy=0.9885, loss=0.0346]\n",
      "Epoch 35 : 100%|██████████| 500/500 [00:33<00:00, 14.75it/s, accuracy=0.9897, loss=0.0301]\n",
      "Epoch 36 : 100%|██████████| 500/500 [00:33<00:00, 14.86it/s, accuracy=0.9890, loss=0.0313]\n",
      "Epoch 37 : 100%|██████████| 500/500 [00:32<00:00, 15.57it/s, accuracy=0.9884, loss=0.0340]\n",
      "Epoch 38 : 100%|██████████| 500/500 [00:33<00:00, 15.12it/s, accuracy=0.9898, loss=0.0303]\n",
      "Epoch 39 : 100%|██████████| 500/500 [00:33<00:00, 14.78it/s, accuracy=0.9895, loss=0.0313]\n",
      "Epoch 40 : 100%|██████████| 500/500 [00:33<00:00, 15.03it/s, accuracy=0.9898, loss=0.0315]\n",
      "Epoch 41 : 100%|██████████| 500/500 [00:33<00:00, 14.88it/s, accuracy=0.9897, loss=0.0307]\n",
      "Epoch 42 : 100%|██████████| 500/500 [00:33<00:00, 14.84it/s, accuracy=0.9893, loss=0.0311]\n",
      "Epoch 43 : 100%|██████████| 500/500 [00:34<00:00, 14.70it/s, accuracy=0.9893, loss=0.0303]\n",
      "Epoch 44 : 100%|██████████| 500/500 [00:33<00:00, 14.78it/s, accuracy=0.9892, loss=0.0302]\n",
      "Epoch 45 : 100%|██████████| 500/500 [00:33<00:00, 14.91it/s, accuracy=0.9907, loss=0.0284]\n",
      "Epoch 46 : 100%|██████████| 500/500 [00:33<00:00, 14.84it/s, accuracy=0.9897, loss=0.0301]\n",
      "Epoch 47 : 100%|██████████| 500/500 [00:33<00:00, 14.99it/s, accuracy=0.9882, loss=0.0355]\n",
      "Epoch 48 : 100%|██████████| 500/500 [00:33<00:00, 15.06it/s, accuracy=0.9896, loss=0.0298]\n",
      "Epoch 49 : 100%|██████████| 500/500 [00:32<00:00, 15.25it/s, accuracy=0.9898, loss=0.0288]\n",
      "Epoch 50 : 100%|██████████| 500/500 [00:32<00:00, 15.32it/s, accuracy=0.9908, loss=0.0275]\n",
      "Epoch 51 : 100%|██████████| 500/500 [00:33<00:00, 15.03it/s, accuracy=0.9895, loss=0.0296]\n",
      "Epoch 52 : 100%|██████████| 500/500 [00:34<00:00, 14.56it/s, accuracy=0.9899, loss=0.0287]\n",
      "Epoch 53 : 100%|██████████| 500/500 [00:33<00:00, 14.75it/s, accuracy=0.9903, loss=0.0287]\n",
      "Epoch 54 : 100%|██████████| 500/500 [00:34<00:00, 14.60it/s, accuracy=0.9902, loss=0.0293]\n",
      "Epoch 55 : 100%|██████████| 500/500 [00:33<00:00, 14.95it/s, accuracy=0.9893, loss=0.0309]\n",
      "Epoch 56 : 100%|██████████| 500/500 [00:34<00:00, 14.52it/s, accuracy=0.9910, loss=0.0264]\n",
      "Epoch 57 : 100%|██████████| 500/500 [00:32<00:00, 15.61it/s, accuracy=0.9892, loss=0.0319]\n",
      "Epoch 58 : 100%|██████████| 500/500 [00:33<00:00, 14.84it/s, accuracy=0.9907, loss=0.0268]\n",
      "Epoch 59 : 100%|██████████| 500/500 [00:33<00:00, 15.14it/s, accuracy=0.9902, loss=0.0295]\n",
      "Epoch 60 : 100%|██████████| 500/500 [00:35<00:00, 14.08it/s, accuracy=0.9919, loss=0.0249]\n",
      "Epoch 61 : 100%|██████████| 500/500 [00:34<00:00, 14.53it/s, accuracy=0.9907, loss=0.0270]\n",
      "Epoch 62 : 100%|██████████| 500/500 [00:32<00:00, 15.29it/s, accuracy=0.9898, loss=0.0295]\n",
      "Epoch 63 : 100%|██████████| 500/500 [00:33<00:00, 14.96it/s, accuracy=0.9906, loss=0.0283]\n",
      "Epoch 64 : 100%|██████████| 500/500 [00:33<00:00, 14.75it/s, accuracy=0.9903, loss=0.0278]\n",
      "Epoch 65 : 100%|██████████| 500/500 [00:34<00:00, 14.49it/s, accuracy=0.9903, loss=0.0286]\n",
      "Epoch 66 : 100%|██████████| 500/500 [00:33<00:00, 14.89it/s, accuracy=0.9910, loss=0.0267]\n",
      "Epoch 67 : 100%|██████████| 500/500 [00:33<00:00, 15.01it/s, accuracy=0.9912, loss=0.0255]\n",
      "Epoch 68 : 100%|██████████| 500/500 [00:34<00:00, 14.65it/s, accuracy=0.9890, loss=0.0323]\n",
      "Epoch 69 : 100%|██████████| 500/500 [00:33<00:00, 14.88it/s, accuracy=0.9903, loss=0.0293]\n",
      "Epoch 70 : 100%|██████████| 500/500 [00:32<00:00, 15.35it/s, accuracy=0.9908, loss=0.0255]\n",
      "Epoch 71 : 100%|██████████| 500/500 [00:32<00:00, 15.47it/s, accuracy=0.9908, loss=0.0275]\n",
      "Epoch 72 : 100%|██████████| 500/500 [00:33<00:00, 14.79it/s, accuracy=0.9892, loss=0.0318]\n",
      "Epoch 73 : 100%|██████████| 500/500 [00:33<00:00, 14.86it/s, accuracy=0.9911, loss=0.0262]\n",
      "Epoch 74 : 100%|██████████| 500/500 [00:34<00:00, 14.43it/s, accuracy=0.9908, loss=0.0264]\n",
      "Epoch 75 : 100%|██████████| 500/500 [00:34<00:00, 14.68it/s, accuracy=0.9897, loss=0.0301]\n",
      "Epoch 76 : 100%|██████████| 500/500 [00:33<00:00, 14.79it/s, accuracy=0.9913, loss=0.0269]\n",
      "Epoch 77 : 100%|██████████| 500/500 [00:33<00:00, 14.77it/s, accuracy=0.9904, loss=0.0271]\n",
      "Epoch 78 : 100%|██████████| 500/500 [00:33<00:00, 14.77it/s, accuracy=0.9910, loss=0.0261]\n",
      "Epoch 79 : 100%|██████████| 500/500 [00:33<00:00, 14.77it/s, accuracy=0.9903, loss=0.0290]\n",
      "Epoch 80 : 100%|██████████| 500/500 [00:34<00:00, 14.36it/s, accuracy=0.9910, loss=0.0264]\n",
      "Epoch 81 : 100%|██████████| 500/500 [00:34<00:00, 14.37it/s, accuracy=0.9916, loss=0.0246]\n",
      "Epoch 82 : 100%|██████████| 500/500 [00:33<00:00, 14.75it/s, accuracy=0.9911, loss=0.0284]\n",
      "Epoch 83 : 100%|██████████| 500/500 [00:34<00:00, 14.52it/s, accuracy=0.9905, loss=0.0288]\n",
      "Epoch 84 : 100%|██████████| 500/500 [00:34<00:00, 14.59it/s, accuracy=0.9907, loss=0.0277]\n",
      "Epoch 85 : 100%|██████████| 500/500 [00:33<00:00, 14.81it/s, accuracy=0.9901, loss=0.0310]\n",
      "Epoch 86 : 100%|██████████| 500/500 [00:33<00:00, 14.73it/s, accuracy=0.9906, loss=0.0272]\n",
      "Epoch 87 : 100%|██████████| 500/500 [00:34<00:00, 14.57it/s, accuracy=0.9907, loss=0.0270]\n",
      "Epoch 88 : 100%|██████████| 500/500 [00:33<00:00, 15.06it/s, accuracy=0.9911, loss=0.0269]\n",
      "Epoch 89 : 100%|██████████| 500/500 [00:33<00:00, 15.03it/s, accuracy=0.9911, loss=0.0263]\n",
      "Epoch 90 : 100%|██████████| 500/500 [00:33<00:00, 15.07it/s, accuracy=0.9920, loss=0.0219]\n",
      "Epoch 91 : 100%|██████████| 500/500 [00:33<00:00, 14.89it/s, accuracy=0.9924, loss=0.0233]\n",
      "Epoch 92 : 100%|██████████| 500/500 [00:32<00:00, 15.32it/s, accuracy=0.9917, loss=0.0256]\n",
      "Epoch 93 : 100%|██████████| 500/500 [00:33<00:00, 14.78it/s, accuracy=0.9914, loss=0.0250]\n",
      "Epoch 94 : 100%|██████████| 500/500 [00:32<00:00, 15.28it/s, accuracy=0.9915, loss=0.0249]\n",
      "Epoch 95 : 100%|██████████| 500/500 [00:34<00:00, 14.70it/s, accuracy=0.9914, loss=0.0243]\n",
      "Epoch 96 : 100%|██████████| 500/500 [00:33<00:00, 14.76it/s, accuracy=0.9923, loss=0.0221]\n",
      "Epoch 97 : 100%|██████████| 500/500 [00:34<00:00, 14.55it/s, accuracy=0.9921, loss=0.0232]\n",
      "Epoch 98 : 100%|██████████| 500/500 [00:33<00:00, 14.87it/s, accuracy=0.9916, loss=0.0240]\n",
      "Epoch 99 : 100%|██████████| 500/500 [00:34<00:00, 14.64it/s, accuracy=0.9922, loss=0.0233]\n",
      "Epoch 100: 100%|██████████| 500/500 [00:32<00:00, 15.47it/s, accuracy=0.9914, loss=0.0259]\n",
      "Epoch 101: 100%|██████████| 500/500 [00:32<00:00, 15.20it/s, accuracy=0.9907, loss=0.0262]\n",
      "Epoch 102: 100%|██████████| 500/500 [00:33<00:00, 14.92it/s, accuracy=0.9917, loss=0.0245]\n",
      "Epoch 103: 100%|██████████| 500/500 [00:32<00:00, 15.30it/s, accuracy=0.9921, loss=0.0228]\n",
      "Epoch 104: 100%|██████████| 500/500 [00:34<00:00, 14.46it/s, accuracy=0.9914, loss=0.0253]\n",
      "Epoch 105: 100%|██████████| 500/500 [00:33<00:00, 14.87it/s, accuracy=0.9918, loss=0.0238]\n",
      "Epoch 106: 100%|██████████| 500/500 [00:33<00:00, 14.72it/s, accuracy=0.9914, loss=0.0255]\n",
      "Epoch 107: 100%|██████████| 500/500 [00:32<00:00, 15.32it/s, accuracy=0.9913, loss=0.0252]\n",
      "Epoch 108: 100%|██████████| 500/500 [00:33<00:00, 14.73it/s, accuracy=0.9921, loss=0.0218]\n",
      "Epoch 109: 100%|██████████| 500/500 [00:32<00:00, 15.38it/s, accuracy=0.9910, loss=0.0252]\n",
      "Epoch 110: 100%|██████████| 500/500 [00:33<00:00, 14.81it/s, accuracy=0.9918, loss=0.0234]\n",
      "Epoch 111: 100%|██████████| 500/500 [00:33<00:00, 15.13it/s, accuracy=0.9907, loss=0.0264]\n",
      "Epoch 112: 100%|██████████| 500/500 [00:33<00:00, 14.72it/s, accuracy=0.9914, loss=0.0255]\n",
      "Epoch 113: 100%|██████████| 500/500 [00:33<00:00, 14.77it/s, accuracy=0.9920, loss=0.0237]\n",
      "Epoch 114: 100%|██████████| 500/500 [00:34<00:00, 14.29it/s, accuracy=0.9911, loss=0.0253]\n",
      "Epoch 115: 100%|██████████| 500/500 [00:34<00:00, 14.50it/s, accuracy=0.9909, loss=0.0269]\n",
      "Epoch 116: 100%|██████████| 500/500 [00:34<00:00, 14.49it/s, accuracy=0.9926, loss=0.0229]\n",
      "Epoch 117: 100%|██████████| 500/500 [00:33<00:00, 14.94it/s, accuracy=0.9919, loss=0.0236]\n",
      "Epoch 118: 100%|██████████| 500/500 [00:34<00:00, 14.66it/s, accuracy=0.9917, loss=0.0238]\n",
      "Epoch 119: 100%|██████████| 500/500 [00:34<00:00, 14.62it/s, accuracy=0.9925, loss=0.0213]\n",
      "Epoch 120: 100%|██████████| 500/500 [00:33<00:00, 14.98it/s, accuracy=0.9912, loss=0.0256]\n",
      "Epoch 121: 100%|██████████| 500/500 [00:33<00:00, 14.80it/s, accuracy=0.9913, loss=0.0259]\n",
      "Epoch 122: 100%|██████████| 500/500 [00:34<00:00, 14.63it/s, accuracy=0.9916, loss=0.0247]\n",
      "Epoch 123: 100%|██████████| 500/500 [00:33<00:00, 14.80it/s, accuracy=0.9930, loss=0.0212]\n",
      "Epoch 124: 100%|██████████| 500/500 [00:33<00:00, 14.87it/s, accuracy=0.9927, loss=0.0227]\n",
      "Epoch 125: 100%|██████████| 500/500 [00:34<00:00, 14.51it/s, accuracy=0.9910, loss=0.0265]\n",
      "Epoch 126: 100%|██████████| 500/500 [00:33<00:00, 14.84it/s, accuracy=0.9912, loss=0.0231]\n",
      "Epoch 127: 100%|██████████| 500/500 [00:31<00:00, 15.74it/s, accuracy=0.9932, loss=0.0213]\n",
      "Epoch 128: 100%|██████████| 500/500 [00:32<00:00, 15.16it/s, accuracy=0.9903, loss=0.0283]\n",
      "Epoch 129: 100%|██████████| 500/500 [00:33<00:00, 15.00it/s, accuracy=0.9920, loss=0.0235]\n",
      "Epoch 130: 100%|██████████| 500/500 [00:33<00:00, 15.02it/s, accuracy=0.9912, loss=0.0241]\n",
      "Epoch 131: 100%|██████████| 500/500 [00:33<00:00, 14.82it/s, accuracy=0.9926, loss=0.0208]\n",
      "Epoch 132: 100%|██████████| 500/500 [00:33<00:00, 14.81it/s, accuracy=0.9915, loss=0.0220]\n",
      "Epoch 133: 100%|██████████| 500/500 [00:33<00:00, 14.73it/s, accuracy=0.9919, loss=0.0237]\n",
      "Epoch 134: 100%|██████████| 500/500 [00:34<00:00, 14.67it/s, accuracy=0.9926, loss=0.0222]\n",
      "Epoch 135: 100%|██████████| 500/500 [00:33<00:00, 14.92it/s, accuracy=0.9923, loss=0.0218]\n",
      "Epoch 136: 100%|██████████| 500/500 [00:34<00:00, 14.55it/s, accuracy=0.9925, loss=0.0227]\n",
      "Epoch 137: 100%|██████████| 500/500 [00:33<00:00, 14.98it/s, accuracy=0.9905, loss=0.0262]\n",
      "Epoch 138: 100%|██████████| 500/500 [00:33<00:00, 15.12it/s, accuracy=0.9914, loss=0.0258]\n",
      "Epoch 139: 100%|██████████| 500/500 [00:33<00:00, 14.85it/s, accuracy=0.9916, loss=0.0259]\n",
      "Epoch 140: 100%|██████████| 500/500 [00:33<00:00, 14.87it/s, accuracy=0.9927, loss=0.0213]\n",
      "Epoch 141: 100%|██████████| 500/500 [00:34<00:00, 14.56it/s, accuracy=0.9904, loss=0.0283]\n",
      "Epoch 142: 100%|██████████| 500/500 [00:33<00:00, 14.82it/s, accuracy=0.9904, loss=0.0276]\n",
      "Epoch 143: 100%|██████████| 500/500 [00:34<00:00, 14.69it/s, accuracy=0.9917, loss=0.0242]\n",
      "Epoch 144: 100%|██████████| 500/500 [00:34<00:00, 14.66it/s, accuracy=0.9903, loss=0.0276]\n",
      "                                                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_892700/2962253735.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#                                    max_batches=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     metalearner.train(meta_train_dataloader,\n\u001b[0m\u001b[1;32m     12\u001b[0m                         \u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/maml_res/maml/metalearners/maml.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataloader, max_batches, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m                 \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0mpostfix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'{0:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_outer_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/maml_res/maml/metalearners/maml.py\u001b[0m in \u001b[0;36mtrain_iter\u001b[0;34m(self, dataloader, max_batches)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                 \u001b[0mouter_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_value = None\n",
    "num_epochs = 200\n",
    "num_batches = 500\n",
    "# Training loop\n",
    "epoch_desc = 'Epoch {{0: <{0}d}}'.format(1 + int(math.log10(num_epochs)))\n",
    "for epoch in range(num_epochs):\n",
    "    #if epoch%10==0:\n",
    "    #    metalearner.calculate_flatness(meta_val_dataloader,\n",
    "    #                                    max_batches=1)\n",
    "                                        \n",
    "    metalearner.train(meta_train_dataloader,\n",
    "                        max_batches=num_batches,\n",
    "                        verbose=True,\n",
    "                        desc='Training',\n",
    "                        leave=False)\n",
    "    results = metalearner.evaluate(meta_val_dataloader,\n",
    "                                    max_batches=num_batches,\n",
    "                                    verbose=True,\n",
    "                                    desc=epoch_desc.format(epoch + 1))\n",
    "\n",
    "    # Save best model\n",
    "    if 'accuracies_after' in results:\n",
    "        if (best_value is None) or (best_value < results['accuracies_after']):\n",
    "            best_value = results['accuracies_after']\n",
    "            save_model = True\n",
    "    elif (best_value is None) or (best_value > results['mean_outer_loss']):\n",
    "        best_value = results['mean_outer_loss']\n",
    "        save_model = True\n",
    "    else:\n",
    "        save_model = False\n",
    "\n",
    "    if save_model:\n",
    "        current_directory = os.getcwd()\n",
    "        final_directory = os.path.join(current_directory, r'models')\n",
    "        if not os.path.isdir(final_directory):\n",
    "                    os.mkdir(final_directory)\n",
    "        torch.save(benchmark.model.state_dict(), './models/sam_omni.pth')\n",
    "\n",
    "if hasattr(benchmark.meta_train_dataset, 'close'):\n",
    "    benchmark.meta_train_dataset.close()\n",
    "    benchmark.meta_val_dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:   2%|▏         | 12/500 [00:02<01:42,  4.76it/s, accuracy=0.2547, loss=1.6896]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_760065/1769806160.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                             pin_memory=True)\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m results2 = metalearner.evaluate(meta_test_dataloader,\n\u001b[0m\u001b[1;32m      8\u001b[0m                                    \u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/maml_res/maml/metalearners/flatmaml.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataloader, max_batches, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mmean_outer_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/maml_res/maml/metalearners/flatmaml.py\u001b[0m in \u001b[0;36mevaluate_iter\u001b[0;34m(self, dataloader, max_batches)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_outer_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/maml_res/maml/metalearners/flatmaml.py\u001b[0m in \u001b[0;36mget_outer_loss\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtest_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mouter_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'outer_losses'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mouter_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mmean_outer_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mouter_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "meta_test_dataloader = BatchMetaDataLoader(benchmark.meta_val_dataset,\n",
    "                                            batch_size=32,\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=2,\n",
    "                                            pin_memory=True)\n",
    "\n",
    "results2 = metalearner.evaluate(meta_test_dataloader,\n",
    "                                   max_batches=500,\n",
    "                                   verbose=True,\n",
    "                                   desc='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 1  : 100%|██████████| 500/500 [00:30<00:00, 16.33it/s, accuracy=0.8871, loss=0.3333]\n",
    "Epoch 2  : 100%|██████████| 500/500 [00:29<00:00, 16.71it/s, accuracy=0.9121, loss=0.2780]\n",
    "Epoch 3  : 100%|██████████| 500/500 [00:30<00:00, 16.53it/s, accuracy=0.9222, loss=0.2342]\n",
    "Epoch 4  : 100%|██████████| 500/500 [00:29<00:00, 16.70it/s, accuracy=0.9322, loss=0.2033]\n",
    "Epoch 5  : 100%|██████████| 500/500 [00:28<00:00, 17.46it/s, accuracy=0.9334, loss=0.2084]\n",
    "Epoch 6  : 100%|██████████| 500/500 [00:30<00:00, 16.61it/s, accuracy=0.9327, loss=0.2093]\n",
    "Epoch 7  : 100%|██████████| 500/500 [00:30<00:00, 16.63it/s, accuracy=0.9342, loss=0.2058]\n",
    "Epoch 8  : 100%|██████████| 500/500 [00:28<00:00, 17.52it/s, accuracy=0.9347, loss=0.2006]\n",
    "Epoch 9  : 100%|██████████| 500/500 [00:30<00:00, 16.27it/s, accuracy=0.9432, loss=0.1772]\n",
    "Epoch 10 : 100%|██████████| 500/500 [00:30<00:00, 16.33it/s, accuracy=0.9344, loss=0.2031]\n",
    "Epoch 11 : 100%|██████████| 500/500 [00:30<00:00, 16.46it/s, accuracy=0.9462, loss=0.1665]\n",
    "Epoch 12 : 100%|██████████| 500/500 [00:30<00:00, 16.67it/s, accuracy=0.9470, loss=0.1661]\n",
    "Epoch 13 : 100%|██████████| 500/500 [00:29<00:00, 17.05it/s, accuracy=0.9538, loss=0.1431]\n",
    "Epoch 14 : 100%|██████████| 500/500 [00:29<00:00, 16.95it/s, accuracy=0.9480, loss=0.1575]\n",
    "Epoch 15 : 100%|██████████| 500/500 [00:30<00:00, 16.57it/s, accuracy=0.9533, loss=0.1425]\n",
    "Epoch 16 : 100%|██████████| 500/500 [00:30<00:00, 16.63it/s, accuracy=0.9582, loss=0.1255]\n",
    "Epoch 17 : 100%|██████████| 500/500 [00:30<00:00, 16.66it/s, accuracy=0.9610, loss=0.1153]\n",
    "Epoch 18 : 100%|██████████| 500/500 [00:30<00:00, 16.65it/s, accuracy=0.9668, loss=0.0998]\n",
    "Epoch 19 : 100%|██████████| 500/500 [00:30<00:00, 16.36it/s, accuracy=0.9644, loss=0.1030]\n",
    "Epoch 20 : 100%|██████████| 500/500 [00:28<00:00, 17.61it/s, accuracy=0.9736, loss=0.0796]\n",
    "Epoch 21 : 100%|██████████| 500/500 [00:28<00:00, 17.68it/s, accuracy=0.9713, loss=0.0826]\n",
    "Epoch 22 : 100%|██████████| 500/500 [00:30<00:00, 16.46it/s, accuracy=0.9745, loss=0.0738]\n",
    "Epoch 23 : 100%|██████████| 500/500 [00:31<00:00, 16.10it/s, accuracy=0.9740, loss=0.0756]\n",
    "Epoch 24 : 100%|██████████| 500/500 [00:30<00:00, 16.21it/s, accuracy=0.9771, loss=0.0680]\n",
    "Epoch 25 : 100%|██████████| 500/500 [00:30<00:00, 16.55it/s, accuracy=0.9732, loss=0.0775]\n",
    "Epoch 26 : 100%|██████████| 500/500 [00:29<00:00, 16.92it/s, accuracy=0.9730, loss=0.0796]\n",
    "Epoch 27 : 100%|██████████| 500/500 [00:30<00:00, 16.63it/s, accuracy=0.9762, loss=0.0722]\n",
    "Epoch 28 : 100%|██████████| 500/500 [00:30<00:00, 16.27it/s, accuracy=0.9777, loss=0.0677]\n",
    "Epoch 29 : 100%|██████████| 500/500 [00:30<00:00, 16.39it/s, accuracy=0.9778, loss=0.0640]\n",
    "Epoch 30 : 100%|██████████| 500/500 [00:30<00:00, 16.25it/s, accuracy=0.9769, loss=0.0686]\n",
    "Epoch 31 : 100%|██████████| 500/500 [00:29<00:00, 16.98it/s, accuracy=0.9734, loss=0.0765]\n",
    "Epoch 32 : 100%|██████████| 500/500 [00:29<00:00, 16.74it/s, accuracy=0.9749, loss=0.0719]\n",
    "Epoch 33 : 100%|██████████| 500/500 [00:30<00:00, 16.42it/s, accuracy=0.9782, loss=0.0640]\n",
    "Epoch 34 : 100%|██████████| 500/500 [00:30<00:00, 16.34it/s, accuracy=0.9777, loss=0.0636]\n",
    "Epoch 35 : 100%|██████████| 500/500 [00:29<00:00, 16.73it/s, accuracy=0.9764, loss=0.0691]\n",
    "Epoch 36 : 100%|██████████| 500/500 [00:30<00:00, 16.62it/s, accuracy=0.9773, loss=0.0684]\n",
    "Epoch 37 : 100%|██████████| 500/500 [00:30<00:00, 16.54it/s, accuracy=0.9778, loss=0.0630]\n",
    "Epoch 38 : 100%|██████████| 500/500 [00:29<00:00, 16.67it/s, accuracy=0.9791, loss=0.0603]\n",
    "Epoch 39 : 100%|██████████| 500/500 [00:30<00:00, 16.24it/s, accuracy=0.9779, loss=0.0639]\n",
    "Epoch 40 : 100%|██████████| 500/500 [00:30<00:00, 16.42it/s, accuracy=0.9782, loss=0.0634]\n",
    "Epoch 41 : 100%|██████████| 500/500 [00:29<00:00, 16.81it/s, accuracy=0.9764, loss=0.0695]\n",
    "Epoch 42 : 100%|██████████| 500/500 [00:30<00:00, 16.27it/s, accuracy=0.9799, loss=0.0594]\n",
    "Epoch 43 : 100%|██████████| 500/500 [00:29<00:00, 16.74it/s, accuracy=0.9794, loss=0.0603]\n",
    "Epoch 44 : 100%|██████████| 500/500 [00:30<00:00, 16.28it/s, accuracy=0.9803, loss=0.0577]\n",
    "Epoch 45 : 100%|██████████| 500/500 [00:30<00:00, 16.19it/s, accuracy=0.9811, loss=0.0575]\n",
    "Epoch 46 : 100%|██████████| 500/500 [00:30<00:00, 16.50it/s, accuracy=0.9783, loss=0.0644]\n",
    "Epoch 47 : 100%|██████████| 500/500 [00:30<00:00, 16.19it/s, accuracy=0.9800, loss=0.0586]\n",
    "Epoch 48 : 100%|██████████| 500/500 [00:30<00:00, 16.46it/s, accuracy=0.9792, loss=0.0609]\n",
    "Epoch 49 : 100%|██████████| 500/500 [00:30<00:00, 16.52it/s, accuracy=0.9810, loss=0.0567]\n",
    "                                                                                         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd1d53b0a861eac4c89bbd16ce82916397ef5b3b9040695bbd2a5c23b8c04acd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
