{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "from collections import OrderedDict\n",
    "from torchmeta.utils.data import BatchMetaDataLoader\n",
    "\n",
    "from maml.datasets import get_benchmark_by_name\n",
    "from maml.metalearners import ModelAgnosticMetaLearning\n",
    "from maml.metalearners import FlatModelAgnosticMetaLearning\n",
    "from maml.metalearners import SamModelAgnosticMetaLearning\n",
    "\n",
    "from sam import SAM\n",
    "from sam_folder.model.smooth_cross_entropy import smooth_crossentropy\n",
    "from sam_folder.utility.bypass_bn import enable_running_stats, disable_running_stats\n",
    "from sam_folder.model.wide_res_net import WideResNet\n",
    "from sam_folder.utility.step_lr import StepLR\n",
    "\n",
    "device = torch.device('cuda' if  torch.cuda.is_available() else 'cpu')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ways=5\n",
    "shots=1\n",
    "meta_lr=0.003\n",
    "fast_lr=0.5\n",
    "meta_batch_size=32\n",
    "\n",
    "benchmark = get_benchmark_by_name('omniglot',\n",
    "                                      './data',\n",
    "                                      ways,\n",
    "                                      shots,\n",
    "                                      shots,\n",
    "                                      hidden_size=64)\n",
    "\n",
    "meta_train_dataloader = BatchMetaDataLoader(benchmark.meta_train_dataset,\n",
    "                                            batch_size=32,\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=2,\n",
    "                                            pin_memory=True)\n",
    "meta_val_dataloader = BatchMetaDataLoader(benchmark.meta_val_dataset,\n",
    "                                            batch_size=16,\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=2,\n",
    "                                            pin_memory=True)\n",
    "\n",
    "meta_optimizer = torch.optim.Adam(benchmark.model.parameters(), lr=meta_lr)\n",
    "#base_optimizer = torch.optim.Adam\n",
    "#meta_optimizer = SAM(benchmark.model.parameters(), base_optimizer, rho=0.05,\n",
    "#                        adaptive=False, lr=meta_lr)\n",
    "metalearner = FlatModelAgnosticMetaLearning(benchmark.model,\n",
    "                                        meta_optimizer,\n",
    "                                        first_order=False,\n",
    "                                        num_adaptation_steps=1,\n",
    "                                        step_size=fast_lr,\n",
    "                                        loss_function=benchmark.loss_function,\n",
    "                                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1  : 100%|██████████| 500/500 [00:32<00:00, 15.34it/s, accuracy=0.9303, loss=0.2116]\n",
      "Epoch 2  : 100%|██████████| 500/500 [00:33<00:00, 15.14it/s, accuracy=0.9535, loss=0.1427]\n",
      "Epoch 3  : 100%|██████████| 500/500 [00:31<00:00, 15.63it/s, accuracy=0.9599, loss=0.1231]\n",
      "Epoch 4  : 100%|██████████| 500/500 [00:33<00:00, 15.00it/s, accuracy=0.9630, loss=0.1142]\n",
      "Epoch 5  : 100%|██████████| 500/500 [00:33<00:00, 14.91it/s, accuracy=0.9678, loss=0.0981]\n",
      "Epoch 6  : 100%|██████████| 500/500 [00:34<00:00, 14.58it/s, accuracy=0.9717, loss=0.0859]\n",
      "Epoch 7  : 100%|██████████| 500/500 [00:33<00:00, 14.81it/s, accuracy=0.9691, loss=0.0995]\n",
      "Epoch 8  : 100%|██████████| 500/500 [00:32<00:00, 15.23it/s, accuracy=0.9653, loss=0.1077]\n",
      "Epoch 9  : 100%|██████████| 500/500 [00:33<00:00, 14.95it/s, accuracy=0.9710, loss=0.0909]\n",
      "Epoch 10 : 100%|██████████| 500/500 [00:32<00:00, 15.31it/s, accuracy=0.9745, loss=0.0777]\n",
      "Epoch 11 : 100%|██████████| 500/500 [00:31<00:00, 15.83it/s, accuracy=0.9750, loss=0.0781]\n",
      "Epoch 12 : 100%|██████████| 500/500 [00:32<00:00, 15.22it/s, accuracy=0.9772, loss=0.0700]\n",
      "Epoch 13 : 100%|██████████| 500/500 [00:32<00:00, 15.34it/s, accuracy=0.9790, loss=0.0648]\n",
      "Epoch 14 : 100%|██████████| 500/500 [00:32<00:00, 15.26it/s, accuracy=0.9808, loss=0.0569]\n",
      "Epoch 15 : 100%|██████████| 500/500 [00:33<00:00, 14.75it/s, accuracy=0.9832, loss=0.0515]\n",
      "Epoch 16 : 100%|██████████| 500/500 [00:32<00:00, 15.21it/s, accuracy=0.9837, loss=0.0497]\n",
      "Epoch 17 : 100%|██████████| 500/500 [00:34<00:00, 14.70it/s, accuracy=0.9842, loss=0.0465]\n",
      "Epoch 18 : 100%|██████████| 500/500 [00:32<00:00, 15.54it/s, accuracy=0.9857, loss=0.0437]\n",
      "Epoch 19 : 100%|██████████| 500/500 [00:34<00:00, 14.60it/s, accuracy=0.9873, loss=0.0356]\n",
      "Epoch 20 : 100%|██████████| 500/500 [00:33<00:00, 14.77it/s, accuracy=0.9873, loss=0.0376]\n",
      "Epoch 21 : 100%|██████████| 500/500 [00:34<00:00, 14.70it/s, accuracy=0.9870, loss=0.0387]\n",
      "Epoch 22 : 100%|██████████| 500/500 [00:32<00:00, 15.19it/s, accuracy=0.9858, loss=0.0408]\n",
      "Epoch 23 : 100%|██████████| 500/500 [00:33<00:00, 15.02it/s, accuracy=0.9880, loss=0.0367]\n",
      "Epoch 24 : 100%|██████████| 500/500 [00:33<00:00, 14.93it/s, accuracy=0.9881, loss=0.0339]\n",
      "Epoch 25 : 100%|██████████| 500/500 [00:33<00:00, 14.86it/s, accuracy=0.9878, loss=0.0355]\n",
      "Epoch 26 : 100%|██████████| 500/500 [00:32<00:00, 15.28it/s, accuracy=0.9874, loss=0.0372]\n",
      "Epoch 27 : 100%|██████████| 500/500 [00:33<00:00, 14.94it/s, accuracy=0.9887, loss=0.0329]\n",
      "Epoch 28 : 100%|██████████| 500/500 [00:34<00:00, 14.62it/s, accuracy=0.9891, loss=0.0331]\n",
      "Epoch 29 : 100%|██████████| 500/500 [00:32<00:00, 15.27it/s, accuracy=0.9900, loss=0.0300]\n",
      "Epoch 30 : 100%|██████████| 500/500 [00:32<00:00, 15.58it/s, accuracy=0.9883, loss=0.0360]\n",
      "Epoch 31 : 100%|██████████| 500/500 [00:32<00:00, 15.35it/s, accuracy=0.9886, loss=0.0333]\n",
      "Epoch 32 : 100%|██████████| 500/500 [00:32<00:00, 15.40it/s, accuracy=0.9893, loss=0.0314]\n",
      "Epoch 33 : 100%|██████████| 500/500 [00:33<00:00, 15.05it/s, accuracy=0.9886, loss=0.0346]\n",
      "Epoch 34 : 100%|██████████| 500/500 [00:33<00:00, 15.01it/s, accuracy=0.9899, loss=0.0296]\n",
      "Epoch 35 : 100%|██████████| 500/500 [00:34<00:00, 14.68it/s, accuracy=0.9883, loss=0.0362]\n",
      "Epoch 36 : 100%|██████████| 500/500 [00:33<00:00, 15.11it/s, accuracy=0.9895, loss=0.0314]\n",
      "Epoch 37 : 100%|██████████| 500/500 [00:34<00:00, 14.45it/s, accuracy=0.9883, loss=0.0344]\n",
      "Epoch 38 : 100%|██████████| 500/500 [00:33<00:00, 14.74it/s, accuracy=0.9892, loss=0.0314]\n",
      "Epoch 39 : 100%|██████████| 500/500 [00:34<00:00, 14.34it/s, accuracy=0.9899, loss=0.0308]\n",
      "Epoch 40 : 100%|██████████| 500/500 [00:33<00:00, 14.85it/s, accuracy=0.9880, loss=0.0337]\n",
      "Epoch 41 : 100%|██████████| 500/500 [00:34<00:00, 14.48it/s, accuracy=0.9893, loss=0.0303]\n",
      "Epoch 42 : 100%|██████████| 500/500 [00:33<00:00, 14.75it/s, accuracy=0.9902, loss=0.0290]\n",
      "Epoch 43 : 100%|██████████| 500/500 [00:33<00:00, 15.06it/s, accuracy=0.9894, loss=0.0308]\n",
      "Epoch 44 : 100%|██████████| 500/500 [00:34<00:00, 14.54it/s, accuracy=0.9896, loss=0.0312]\n",
      "Epoch 45 : 100%|██████████| 500/500 [00:33<00:00, 14.89it/s, accuracy=0.9906, loss=0.0287]\n",
      "Epoch 46 : 100%|██████████| 500/500 [00:32<00:00, 15.16it/s, accuracy=0.9896, loss=0.0302]\n",
      "Epoch 47 : 100%|██████████| 500/500 [00:32<00:00, 15.22it/s, accuracy=0.9901, loss=0.0289]\n",
      "Epoch 48 : 100%|██████████| 500/500 [00:32<00:00, 15.41it/s, accuracy=0.9918, loss=0.0249]\n",
      "Epoch 49 : 100%|██████████| 500/500 [00:32<00:00, 15.45it/s, accuracy=0.9897, loss=0.0295]\n",
      "Epoch 50 : 100%|██████████| 500/500 [00:33<00:00, 14.95it/s, accuracy=0.9908, loss=0.0280]\n",
      "Epoch 51 : 100%|██████████| 500/500 [00:32<00:00, 15.28it/s, accuracy=0.9900, loss=0.0299]\n",
      "Epoch 52 : 100%|██████████| 500/500 [00:33<00:00, 14.97it/s, accuracy=0.9887, loss=0.0326]\n",
      "Epoch 53 : 100%|██████████| 500/500 [00:33<00:00, 15.09it/s, accuracy=0.9899, loss=0.0283]\n",
      "Epoch 54 : 100%|██████████| 500/500 [00:32<00:00, 15.15it/s, accuracy=0.9916, loss=0.0261]\n",
      "Epoch 55 : 100%|██████████| 500/500 [00:33<00:00, 14.71it/s, accuracy=0.9922, loss=0.0249]\n",
      "Epoch 56 : 100%|██████████| 500/500 [00:33<00:00, 14.96it/s, accuracy=0.9904, loss=0.0272]\n",
      "Epoch 57 : 100%|██████████| 500/500 [00:32<00:00, 15.29it/s, accuracy=0.9899, loss=0.0312]\n",
      "Epoch 58 : 100%|██████████| 500/500 [00:33<00:00, 14.78it/s, accuracy=0.9900, loss=0.0278]\n",
      "Epoch 59 : 100%|██████████| 500/500 [00:33<00:00, 14.93it/s, accuracy=0.9913, loss=0.0256]\n",
      "Epoch 60 : 100%|██████████| 500/500 [00:32<00:00, 15.39it/s, accuracy=0.9905, loss=0.0276]\n",
      "Epoch 61 : 100%|██████████| 500/500 [00:32<00:00, 15.47it/s, accuracy=0.9905, loss=0.0283]\n",
      "Epoch 62 : 100%|██████████| 500/500 [00:33<00:00, 15.04it/s, accuracy=0.9897, loss=0.0307]\n",
      "Epoch 63 : 100%|██████████| 500/500 [00:33<00:00, 15.05it/s, accuracy=0.9898, loss=0.0289]\n",
      "Epoch 64 : 100%|██████████| 500/500 [00:32<00:00, 15.41it/s, accuracy=0.9909, loss=0.0267]\n",
      "Epoch 65 : 100%|██████████| 500/500 [00:33<00:00, 15.01it/s, accuracy=0.9902, loss=0.0286]\n",
      "Epoch 66 : 100%|██████████| 500/500 [00:33<00:00, 14.85it/s, accuracy=0.9919, loss=0.0251]\n",
      "Epoch 67 : 100%|██████████| 500/500 [00:32<00:00, 15.34it/s, accuracy=0.9908, loss=0.0271]\n",
      "Epoch 68 : 100%|██████████| 500/500 [00:33<00:00, 15.02it/s, accuracy=0.9920, loss=0.0226]\n",
      "Epoch 69 : 100%|██████████| 500/500 [00:31<00:00, 15.65it/s, accuracy=0.9907, loss=0.0272]\n",
      "Epoch 70 : 100%|██████████| 500/500 [00:33<00:00, 15.15it/s, accuracy=0.9922, loss=0.0240]\n",
      "Epoch 71 : 100%|██████████| 500/500 [00:32<00:00, 15.40it/s, accuracy=0.9915, loss=0.0255]\n",
      "Epoch 72 : 100%|██████████| 500/500 [00:32<00:00, 15.35it/s, accuracy=0.9894, loss=0.0324]\n",
      "Epoch 73 : 100%|██████████| 500/500 [00:32<00:00, 15.52it/s, accuracy=0.9906, loss=0.0276]\n",
      "Epoch 74 : 100%|██████████| 500/500 [00:32<00:00, 15.55it/s, accuracy=0.9920, loss=0.0236]\n",
      "Epoch 75 : 100%|██████████| 500/500 [00:33<00:00, 14.84it/s, accuracy=0.9919, loss=0.0238]\n",
      "Epoch 76 : 100%|██████████| 500/500 [00:33<00:00, 14.94it/s, accuracy=0.9918, loss=0.0234]\n",
      "Epoch 77 : 100%|██████████| 500/500 [00:33<00:00, 14.95it/s, accuracy=0.9908, loss=0.0269]\n",
      "Epoch 78 : 100%|██████████| 500/500 [00:32<00:00, 15.22it/s, accuracy=0.9901, loss=0.0278]\n",
      "Epoch 79 : 100%|██████████| 500/500 [00:33<00:00, 14.85it/s, accuracy=0.9918, loss=0.0244]\n",
      "Epoch 80 : 100%|██████████| 500/500 [00:32<00:00, 15.23it/s, accuracy=0.9919, loss=0.0231]\n",
      "Epoch 81 : 100%|██████████| 500/500 [00:32<00:00, 15.32it/s, accuracy=0.9910, loss=0.0254]\n",
      "Epoch 82 : 100%|██████████| 500/500 [00:33<00:00, 14.79it/s, accuracy=0.9915, loss=0.0260]\n",
      "Epoch 83 : 100%|██████████| 500/500 [00:33<00:00, 14.96it/s, accuracy=0.9911, loss=0.0250]\n",
      "Epoch 84 : 100%|██████████| 500/500 [00:34<00:00, 14.60it/s, accuracy=0.9910, loss=0.0258]\n",
      "Epoch 85 : 100%|██████████| 500/500 [00:33<00:00, 14.85it/s, accuracy=0.9909, loss=0.0262]\n",
      "Epoch 86 : 100%|██████████| 500/500 [00:32<00:00, 15.34it/s, accuracy=0.9915, loss=0.0259]\n",
      "Epoch 87 : 100%|██████████| 500/500 [00:33<00:00, 15.15it/s, accuracy=0.9910, loss=0.0253]\n",
      "Epoch 88 : 100%|██████████| 500/500 [00:32<00:00, 15.54it/s, accuracy=0.9919, loss=0.0238]\n",
      "Epoch 89 : 100%|██████████| 500/500 [00:32<00:00, 15.23it/s, accuracy=0.9910, loss=0.0259]\n",
      "Epoch 90 : 100%|██████████| 500/500 [00:33<00:00, 14.99it/s, accuracy=0.9908, loss=0.0277]\n",
      "Epoch 91 : 100%|██████████| 500/500 [00:33<00:00, 15.00it/s, accuracy=0.9922, loss=0.0233]\n",
      "Epoch 92 : 100%|██████████| 500/500 [00:33<00:00, 15.03it/s, accuracy=0.9922, loss=0.0225]\n",
      "Epoch 93 : 100%|██████████| 500/500 [00:32<00:00, 15.43it/s, accuracy=0.9917, loss=0.0231]\n",
      "Epoch 94 : 100%|██████████| 500/500 [00:32<00:00, 15.39it/s, accuracy=0.9923, loss=0.0220]\n",
      "Epoch 95 : 100%|██████████| 500/500 [00:33<00:00, 14.87it/s, accuracy=0.9910, loss=0.0249]\n",
      "Epoch 96 : 100%|██████████| 500/500 [00:33<00:00, 15.06it/s, accuracy=0.9903, loss=0.0283]\n",
      "Epoch 97 : 100%|██████████| 500/500 [00:33<00:00, 15.10it/s, accuracy=0.9909, loss=0.0271]\n",
      "Epoch 98 : 100%|██████████| 500/500 [00:32<00:00, 15.36it/s, accuracy=0.9915, loss=0.0249]\n",
      "Epoch 99 : 100%|██████████| 500/500 [00:32<00:00, 15.21it/s, accuracy=0.9921, loss=0.0230]\n",
      "Epoch 100: 100%|██████████| 500/500 [00:33<00:00, 14.96it/s, accuracy=0.9931, loss=0.0205]\n",
      "Epoch 101: 100%|██████████| 500/500 [00:33<00:00, 15.01it/s, accuracy=0.9903, loss=0.0279]\n",
      "Epoch 102: 100%|██████████| 500/500 [00:32<00:00, 15.39it/s, accuracy=0.9920, loss=0.0239]\n",
      "Epoch 103: 100%|██████████| 500/500 [00:33<00:00, 14.79it/s, accuracy=0.9897, loss=0.0307]\n",
      "Epoch 104: 100%|██████████| 500/500 [00:33<00:00, 15.11it/s, accuracy=0.9910, loss=0.0268]\n",
      "Epoch 105: 100%|██████████| 500/500 [00:32<00:00, 15.33it/s, accuracy=0.9930, loss=0.0212]\n",
      "Epoch 106: 100%|██████████| 500/500 [00:32<00:00, 15.46it/s, accuracy=0.9917, loss=0.0235]\n",
      "Epoch 107: 100%|██████████| 500/500 [00:33<00:00, 15.15it/s, accuracy=0.9915, loss=0.0260]\n",
      "Epoch 108: 100%|██████████| 500/500 [00:32<00:00, 15.27it/s, accuracy=0.9917, loss=0.0256]\n",
      "Epoch 109: 100%|██████████| 500/500 [00:31<00:00, 15.88it/s, accuracy=0.9907, loss=0.0268]\n",
      "Epoch 110: 100%|██████████| 500/500 [00:33<00:00, 14.80it/s, accuracy=0.9917, loss=0.0238]\n",
      "Epoch 111: 100%|██████████| 500/500 [00:33<00:00, 14.95it/s, accuracy=0.9920, loss=0.0229]\n",
      "Epoch 112: 100%|██████████| 500/500 [00:33<00:00, 14.77it/s, accuracy=0.9913, loss=0.0257]\n",
      "Epoch 113: 100%|██████████| 500/500 [00:32<00:00, 15.52it/s, accuracy=0.9922, loss=0.0249]\n",
      "Epoch 114: 100%|██████████| 500/500 [00:33<00:00, 14.72it/s, accuracy=0.9920, loss=0.0239]\n",
      "Epoch 115: 100%|██████████| 500/500 [00:32<00:00, 15.28it/s, accuracy=0.9926, loss=0.0230]\n",
      "Epoch 116: 100%|██████████| 500/500 [00:33<00:00, 14.89it/s, accuracy=0.9912, loss=0.0268]\n",
      "Epoch 117: 100%|██████████| 500/500 [00:32<00:00, 15.48it/s, accuracy=0.9916, loss=0.0240]\n",
      "Epoch 118: 100%|██████████| 500/500 [00:33<00:00, 15.13it/s, accuracy=0.9914, loss=0.0260]\n",
      "Epoch 119: 100%|██████████| 500/500 [00:32<00:00, 15.34it/s, accuracy=0.9918, loss=0.0242]\n",
      "Epoch 120: 100%|██████████| 500/500 [00:33<00:00, 14.93it/s, accuracy=0.9929, loss=0.0213]\n",
      "Epoch 121: 100%|██████████| 500/500 [00:33<00:00, 15.11it/s, accuracy=0.9916, loss=0.0239]\n",
      "Epoch 122: 100%|██████████| 500/500 [00:33<00:00, 14.76it/s, accuracy=0.9919, loss=0.0247]\n",
      "Epoch 123: 100%|██████████| 500/500 [00:34<00:00, 14.51it/s, accuracy=0.9913, loss=0.0247]\n",
      "Epoch 124: 100%|██████████| 500/500 [00:33<00:00, 14.89it/s, accuracy=0.9924, loss=0.0238]\n",
      "Epoch 125: 100%|██████████| 500/500 [00:33<00:00, 14.98it/s, accuracy=0.9925, loss=0.0223]\n",
      "Epoch 126: 100%|██████████| 500/500 [00:32<00:00, 15.32it/s, accuracy=0.9917, loss=0.0240]\n",
      "Epoch 127: 100%|██████████| 500/500 [00:32<00:00, 15.34it/s, accuracy=0.9906, loss=0.0265]\n",
      "Epoch 128: 100%|██████████| 500/500 [00:31<00:00, 15.66it/s, accuracy=0.9909, loss=0.0269]\n",
      "Epoch 129: 100%|██████████| 500/500 [00:33<00:00, 15.04it/s, accuracy=0.9923, loss=0.0222]\n",
      "Epoch 130: 100%|██████████| 500/500 [00:33<00:00, 15.01it/s, accuracy=0.9916, loss=0.0254]\n",
      "Epoch 131: 100%|██████████| 500/500 [00:33<00:00, 15.01it/s, accuracy=0.9926, loss=0.0227]\n",
      "Epoch 132: 100%|██████████| 500/500 [00:33<00:00, 14.85it/s, accuracy=0.9924, loss=0.0222]\n",
      "Epoch 133: 100%|██████████| 500/500 [00:32<00:00, 15.47it/s, accuracy=0.9918, loss=0.0232]\n",
      "Epoch 134: 100%|██████████| 500/500 [00:34<00:00, 14.54it/s, accuracy=0.9916, loss=0.0244]\n",
      "Epoch 135: 100%|██████████| 500/500 [00:33<00:00, 15.01it/s, accuracy=0.9915, loss=0.0252]\n",
      "Epoch 136: 100%|██████████| 500/500 [00:33<00:00, 14.79it/s, accuracy=0.9919, loss=0.0229]\n",
      "Epoch 137: 100%|██████████| 500/500 [00:34<00:00, 14.50it/s, accuracy=0.9910, loss=0.0274]\n",
      "Epoch 138: 100%|██████████| 500/500 [00:33<00:00, 14.75it/s, accuracy=0.9924, loss=0.0226]\n",
      "Epoch 139: 100%|██████████| 500/500 [00:31<00:00, 15.65it/s, accuracy=0.9914, loss=0.0259]\n",
      "Epoch 140: 100%|██████████| 500/500 [00:33<00:00, 14.88it/s, accuracy=0.9922, loss=0.0233]\n",
      "                                                                                         \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_893919/3131206442.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#                                    max_batches=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     metalearner.train(meta_train_dataloader,\n\u001b[0m\u001b[1;32m     12\u001b[0m                         \u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/maml_res/maml/metalearners/flatmaml.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataloader, max_batches, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m                 \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mpostfix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'{0:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_outer_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/maml_res/maml/metalearners/flatmaml.py\u001b[0m in \u001b[0;36mtrain_iter\u001b[0;34m(self, dataloader, max_batches)\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0;31m#for p in self.model.parameters():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;31m#    p.grad.data.mul_(1.0 / M)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                 \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_value = None\n",
    "num_epochs = 200\n",
    "num_batches = 500\n",
    "# Training loop\n",
    "epoch_desc = 'Epoch {{0: <{0}d}}'.format(1 + int(math.log10(num_epochs)))\n",
    "for epoch in range(num_epochs):\n",
    "    #if epoch%10==0:\n",
    "    #    metalearner.calculate_flatness(meta_val_dataloader,\n",
    "    #                                    max_batches=1)\n",
    "                                        \n",
    "    metalearner.train(meta_train_dataloader,\n",
    "                        max_batches=num_batches,\n",
    "                        verbose=True,\n",
    "                        desc='Training',\n",
    "                        leave=False)\n",
    "    results = metalearner.evaluate(meta_val_dataloader,\n",
    "                                    max_batches=num_batches,\n",
    "                                    verbose=True,\n",
    "                                    desc=epoch_desc.format(epoch + 1))\n",
    "\n",
    "    # Save best model\n",
    "    if 'accuracies_after' in results:\n",
    "        if (best_value is None) or (best_value < results['accuracies_after']):\n",
    "            best_value = results['accuracies_after']\n",
    "            save_model = True\n",
    "    elif (best_value is None) or (best_value > results['mean_outer_loss']):\n",
    "        best_value = results['mean_outer_loss']\n",
    "        save_model = True\n",
    "    else:\n",
    "        save_model = False\n",
    "\n",
    "    if save_model:\n",
    "        current_directory = os.getcwd()\n",
    "        final_directory = os.path.join(current_directory, r'models')\n",
    "        if not os.path.isdir(final_directory):\n",
    "                    os.mkdir(final_directory)\n",
    "        torch.save(benchmark.model.state_dict(), './models/flat_maml.pth')\n",
    "\n",
    "if hasattr(benchmark.meta_train_dataset, 'close'):\n",
    "    benchmark.meta_train_dataset.close()\n",
    "    benchmark.meta_val_dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd1d53b0a861eac4c89bbd16ce82916397ef5b3b9040695bbd2a5c23b8c04acd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
